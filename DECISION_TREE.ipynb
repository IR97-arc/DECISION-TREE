{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHRk4Xuflcvd"
      },
      "outputs": [],
      "source": [
        "1. * Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "2. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the\n",
        "feature importances*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier using Gini Impurity\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print feature importances\n",
        "print(feature_importances_df)\n",
        "\n",
        "\n",
        "3. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the\n",
        "model accuracy*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier using Entropy\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "4. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean\n",
        "Squared Error (MSE)*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate and print the Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "\n",
        "\n",
        "5. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Export the Decision Tree to a DOT file\n",
        "dot_data = export_graphviz(clf, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Visualize the Decision Tree using graphviz\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree\")\n",
        "\n",
        "print(\"Decision Tree visualization saved as decision_tree.pdf\")\n",
        "\n",
        "\n",
        "6. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its\n",
        "accuracy with a fully grown tree*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a fully grown Decision Tree Classifier\n",
        "full_tree = DecisionTreeClassifier(random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "y_pred_full = full_tree.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Train a Decision Tree Classifier with a maximum depth of 3\n",
        "limited_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "limited_tree.fit(X_train, y_train)\n",
        "y_pred_limited = limited_tree.predict(X_test)\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "# Compare the accuracy of both trees\n",
        "print(f\"Accuracy of fully grown tree: {accuracy_full:.2f}\")\n",
        "print(f\"Accuracy of tree with max depth 3: {accuracy_limited:.2f}\")\n",
        "\n",
        "# Check if limiting the depth improves or worsens the accuracy\n",
        "if accuracy_limited > accuracy_full:\n",
        "    print(\"Limiting the depth improves the accuracy.\")\n",
        "elif accuracy_limited < accuracy_full:\n",
        "    print(\"Limiting the depth worsens the accuracy.\")\n",
        "else:\n",
        "    print(\"Limiting the depth does not affect the accuracy.\")\n",
        "\n",
        "7. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its\n",
        "accuracy with a default tree*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a default Decision Tree Classifier\n",
        "default_tree = DecisionTreeClassifier(random_state=42)\n",
        "default_tree.fit(X_train, y_train)\n",
        "y_pred_default = default_tree.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "# Train a Decision Tree Classifier with min_samples_split=5\n",
        "min_samples_tree = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "min_samples_tree.fit(X_train, y_train)\n",
        "y_pred_min_samples = min_samples_tree.predict(X_test)\n",
        "accuracy_min_samples = accuracy_score(y_test, y_pred_min_samples)\n",
        "\n",
        "# Compare the accuracy of both trees\n",
        "print(f\"Accuracy of default tree: {accuracy_default:.2f}\")\n",
        "print(f\"Accuracy of tree with min_samples_split=5: {accuracy_min_samples:.2f}\")\n",
        "\n",
        "# Check if using min_samples_split improves or worsens the accuracy\n",
        "if accuracy_min_samples > accuracy_default:\n",
        "    print(\"Using min_samples_split=5 improves the accuracy.\")\n",
        "elif accuracy_min_samples < accuracy_default:\n",
        "    print(\"Using min_samples_split=5 worsens the accuracy.\")\n",
        "else:\n",
        "    print(\"Using min_samples_split=5 does not affect the accuracy.\")\n",
        "\n",
        "\n",
        "8. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its\n",
        "accuracy with unscaled data\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier on unscaled data\n",
        "unscaled_tree = DecisionTreeClassifier(random_state=42)\n",
        "unscaled_tree.fit(X_train, y_train)\n",
        "y_pred_unscaled = unscaled_tree.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "\n",
        "# Apply feature scaling using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Decision Tree Classifier on scaled data\n",
        "scaled_tree = DecisionTreeClassifier(random_state=42)\n",
        "scaled_tree.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = scaled_tree.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Compare the accuracy of both trees\n",
        "print(f\"Accuracy of tree on unscaled data: {accuracy_unscaled:.2f}\")\n",
        "print(f\"Accuracy of tree on scaled data: {accuracy_scaled:.2f}\")\n",
        "\n",
        "# Check if feature scaling improves or worsens the accuracy\n",
        "if accuracy_scaled > accuracy_unscaled:\n",
        "    print(\"Feature scaling improves the accuracy.\")\n",
        "elif accuracy_scaled < accuracy_unscaled:\n",
        "    print(\"Feature scaling worsens the accuracy.\")\n",
        "else:\n",
        "    print(\"Feature scaling does not affect the accuracy.\")\n",
        "\n",
        "9. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass\n",
        "classification*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier using One-vs-Rest (OvR) strategy\n",
        "ovr_tree = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovr_tree.fit(X_train, y_train)\n",
        "y_pred_ovr = ovr_tree.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the OvR classifier\n",
        "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "print(f\"Accuracy of OvR classifier: {accuracy_ovr:.2f}\")\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_ovr))\n",
        "\n",
        "10. Write a Python program to train a Decision Tree Classifier and display the feature importance scores*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.target_names\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importance scores\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'Feature': iris.feature_names,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importance scores\n",
        "print(feature_importances_df)\n",
        "\n",
        "11. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance\n",
        "with an unrestricted tree\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an unrestricted Decision Tree Regressor\n",
        "unrestricted_tree = DecisionTreeRegressor(random_state=42)\n",
        "unrestricted_tree.fit(X_train, y_train)\n",
        "y_pred_unrestricted = unrestricted_tree.predict(X_test)\n",
        "mse_unrestricted = mean_squared_error(y_test, y_pred_unrestricted)\n",
        "rmse_unrestricted = np.sqrt(mse_unrestricted)\n",
        "\n",
        "# Train a Decision Tree Regressor with max_depth=5\n",
        "restricted_tree = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "restricted_tree.fit(X_train, y_train)\n",
        "y_pred_restricted = restricted_tree.predict(X_test)\n",
        "mse_restricted = mean_squared_error(y_test, y_pred_restricted)\n",
        "rmse_restricted = np.sqrt(mse_restricted)\n",
        "\n",
        "# Compare the performance of both trees\n",
        "print(f\"RMSE of unrestricted tree: {rmse_unrestricted:.2f}\")\n",
        "print(f\"RMSE of tree with max_depth=5: {rmse_restricted:.2f}\")\n",
        "\n",
        "# Check if restricting the depth improves or worsens the performance\n",
        "if rmse_restricted < rmse_unrestricted:\n",
        "    print(\"Restricting the depth improves the performance.\")\n",
        "elif rmse_restricted > rmse_unrestricted:\n",
        "    print(\"Restricting the depth worsens the performance.\")\n",
        "else:\n",
        "    print(\"Restricting the depth does not affect the performance.\")\n",
        "\n",
        "\n",
        "12. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and\n",
        "visualize its effect on accuracy*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier and get the path for CCP\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "# Train Decision Tree Classifiers with different alpha values\n",
        "accuracies = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Visualize the effect of CCP on accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ccp_alphas, accuracies, marker='o')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Effect of Cost Complexity Pruning on Accuracy')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "13. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision,\n",
        "Recall, and F1-Score*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "14. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn*\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d',\n",
        "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "15. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values\n",
        "for max_depth and min_samples_split.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Score: {grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Train a Decision Tree Classifier with the best parameters\n",
        "best_clf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on Test Set: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}